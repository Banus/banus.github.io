<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Emanuele Plebani </title> <meta name="author" content="Emanuele Plebani"> <meta name="description" content="publications by year in reverse chronological order."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://banus.github.io/publications/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Emanuele</span> Plebani </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/patents/">patents </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by year in reverse chronological order.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Shemonti2023novel" class="col-sm-8"> <div class="title">A Novel Statistical Methodology for Quantifying the Spatial Arrangements of Axons in Peripheral Nerves</div> <div class="author"> <a href="https://sites.google.com/view/abida-sanjana-shemonti" rel="external nofollow noopener" target="_blank">Abida Sanjana Shemonti</a>, <em>Emanuele Plebani</em>, <a href="https://www.linkedin.com/in/nataliabiscola" rel="external nofollow noopener" target="_blank">Natalia P. Biscola</a>, Deborah M. Jaffey, <a href="https://profiles.mountsinai.org/leif-anders-havton" rel="external nofollow noopener" target="_blank">Leif A. Havton</a>, Janet R. Keast, Alex Pothen, <a href="https://cs.iupui.edu/~mdundar/" rel="external nofollow noopener" target="_blank">M. Murat Dundar</a>, Terry L. Powley, and <a href="https://web.ics.purdue.edu/~brajwa/" rel="external nofollow noopener" target="_blank">Bartek Rajwa</a> </div> <div class="periodical"> <em>Frontiers in Neuroscience</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3389/fnins.2023.1072779" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2210.09554" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2023.1072779/full" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>A thorough understanding of the neuroanatomy of peripheral nerves is required for a better insight into their function and the development of neuromodulation tools and strategies. In biophysical modeling, it is commonly assumed that the complex spatial arrangement of myelinated and unmyelinated axons in peripheral nerves is random, however, in reality the axonal organization is inhomogeneous and anisotropic. Present quantitative neuroanatomy methods analyze peripheral nerves in terms of the number of axons and the morphometric characteristics of the axons, such as area and diameter. In this study, we employed spatial statistics and point process models to describe the spatial arrangement of axons and Sinkhorn distances to compute the similarities between these arrangements (in terms of first- and second-order statistics) in various vagus and pelvic nerve cross-sections. We utilized high-resolution transmission electron microscopy (TEM) images that have been segmented using a custom-built high-throughput deep learning system based on a highly modified U-Net architecture. Our findings show a novel and innovative approach to quantifying similarities between spatial point patterns using metrics derived from the solution to the optimal transport problem. We also present a generalizable pipeline for quantitative analysis of peripheral nerve architecture. Our data demonstrate differences between male- and female-originating samples and similarities between the pelvic and abdominal vagus nerves.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Shemonti2023novel</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Novel Statistical Methodology for Quantifying the Spatial Arrangements of Axons in Peripheral Nerves}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shemonti, Abida Sanjana and Plebani, Emanuele and Biscola, Natalia P. and Jaffey, Deborah M. and Havton, Leif A. and Keast, Janet R. and Pothen, Alex and Dundar, M. Murat and Powley, Terry L. and Rajwa, Bartek}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Neuroscience}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1662-453X}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3389/fnins.2023.1072779}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Karimi2022Textflow" class="col-sm-8"> <div class="title">Textflow: Toward Supporting Screen-free Manipulation of Situation-Relevant Smart Messages</div> <div class="author"> <a href="https://www.linkedin.com/in/pegah-karimi-9194b4126" rel="external nofollow noopener" target="_blank">Pegah Karimi</a>, <em>Emanuele Plebani</em>, <a href="https://aqueashamarie.com/" rel="external nofollow noopener" target="_blank">Aqueasha Martin-Hammond</a>, and <a href="https://luddy.iupui.edu/contact/profile/davide-bolchini" rel="external nofollow noopener" target="_blank">Davide Bolchini</a> </div> <div class="periodical"> <em>ACM Transactions on Interactive Intelligent Systems</em>, Nov 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3519263" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1145/3519263" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Texting relies on screen-centric prompts designed for sighted users, still posing significant barriers to people who are blind and visually impaired (BVI). Can we re-imagine texting untethered from a visual display? In an interview study, 20 BVI adults shared situations surrounding their texting practices, recurrent topics of conversations, and challenges. Informed by these insights, we introduce TextFlow, a mixed-initiative context-aware system that generates entirely auditory message options relevant to the users’ location, activity, and time of the day. Users can browse and select suggested aural messages using finger-taps supported by an off-the-shelf finger-worn device without having to hold or attend to a mobile screen. In an evaluative study, 10 BVI participants successfully interacted with TextFlow to browse and send messages in screen-free mode. The experiential response of the users shed light on the importance of bypassing the phone and accessing rapidly controllable messages at their fingertips while preserving privacy and accuracy with respect to speech or screen-based input. We discuss how non-visual access to proactive, contextual messaging can support the blind in a variety of daily scenarios.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Karimi2022Textflow</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Textflow: {{Toward Supporting Screen-free Manipulation}} of {{Situation-Relevant Smart Messages}}}</span><span class="p">,</span>
  <span class="na">shorttitle</span> <span class="p">=</span> <span class="s">{Textflow}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Karimi, Pegah and Plebani, Emanuele and Martin-Hammond, Aqueasha and Bolchini, Davide}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Transactions on Interactive Intelligent Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{31:1--31:29}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2160-6455}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3519263}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/umf_unet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="umf_unet.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Plebani2022Highthroughput" class="col-sm-8"> <div class="title">High-Throughput Segmentation of Unmyelinated Axons by Deep Learning</div> <div class="author"> <em>Emanuele Plebani</em>, <a href="https://www.linkedin.com/in/nataliabiscola" rel="external nofollow noopener" target="_blank">Natalia P. Biscola</a>, <a href="https://profiles.mountsinai.org/leif-anders-havton" rel="external nofollow noopener" target="_blank">Leif A. Havton</a>, <a href="https://web.ics.purdue.edu/~brajwa/" rel="external nofollow noopener" target="_blank">Bartek Rajwa</a>, <a href="https://sites.google.com/view/abida-sanjana-shemonti" rel="external nofollow noopener" target="_blank">Abida Sanjana Shemonti</a>, Deborah Jaffey, Terry Powley, Janet R. Keast, Kun-Han Lu, and <a href="https://cs.iupui.edu/~mdundar/" rel="external nofollow noopener" target="_blank">M. Murat Dundar</a> </div> <div class="periodical"> <em>Scientific Reports</em>, Jan 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1038/s41598-022-04854-3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.nature.com/articles/s41598-022-04854-3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/Banus/umf_unet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="../projects/tem_segmentation/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="abstract hidden"> <p>Axonal characterizations of connectomes in healthy and disease phenotypes are surprisingly incomplete and biased because unmyelinated axons, the most prevalent type of fibers in the nervous system, have largely been ignored as their quantitative assessment quickly becomes unmanageable as the number of axons increases. Herein, we introduce the first prototype of a high-throughput processing pipeline for automated segmentation of unmyelinated fibers. Our team has used transmission electron microscopy images of vagus and pelvic nerves in rats. All unmyelinated axons in these images are individually annotated and used as labeled data to train and validate a deep instance segmentation network. We investigate the effect of different training strategies on the overall segmentation accuracy of the network. We extensively validate the segmentation algorithm as a stand-alone segmentation tool as well as in an expert-in-the-loop hybrid segmentation setting with preliminary, albeit remarkably encouraging results. Our algorithm achieves an instance-level \(F_1\) score of between 0.7 and 0.9 on various test images in the stand-alone mode and reduces expert annotation labor by 80% in the hybrid setting. We hope that this new high-throughput segmentation pipeline will enable quick and accurate characterization of unmyelinated fibers at scale and become instrumental in significantly advancing our understanding of connectomes in both the peripheral and the central nervous systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Plebani2022Highthroughput</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{High-Throughput Segmentation of Unmyelinated Axons by Deep Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Plebani, Emanuele and Biscola, Natalia P. and Havton, Leif A. and Rajwa, Bartek and Shemonti, Abida Sanjana and Jaffey, Deborah and Powley, Terry and Keast, Janet R. and Lu, Kun-Han and Dundar, M. Murat}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific Reports}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1198}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Nature Publishing Group}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2045-2322}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s41598-022-04854-3}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Plebani2022machine" class="col-sm-8"> <div class="title">A Machine Learning Toolkit for CRISM Image Analysis</div> <div class="author"> <em>Emanuele Plebani</em>, <a href="https://www.ehlmann.caltech.edu/people/ehlmann.html" rel="external nofollow noopener" target="_blank">Bethany L. Ehlmann</a>, <a href="https://www.linkedin.com/in/ellenleask" rel="external nofollow noopener" target="_blank">Ellen K. Leask</a>, Valerie K. Fox, and <a href="https://cs.iupui.edu/~mdundar/" rel="external nofollow noopener" target="_blank">M. Murat Dundar</a> </div> <div class="periodical"> <em>Icarus</em>, Apr 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.icarus.2021.114849" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0019103521004905" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://ars.els-cdn.com/content/image/1-s2.0-S0019103521004905-mmc1.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> <a href="https://github.com/Banus/crism_ml" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="../projects/crism/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="abstract hidden"> <p>Hyperspectral images collected by remote sensing have played a significant role in the discovery of aqueous alteration minerals, which in turn have important implications for our understanding of the changing habitability on Mars. Traditional spectral analyzes based on summary parameters have been helpful in converting hyperspectral cubes into readily visualizable three channel maps highlighting high-level mineral composition of the Martian terrain. These maps have been used as a starting point in the search for specific mineral phases in images. Although the amount of labor needed to verify the presence of a mineral phase in an image is quite limited for phases that emerge with high abundance, manual processing becomes laborious when the task involves determining the spatial extent of detected phases or identifying small outcrops of secondary phases that appear in only a few pixels within an image. Thanks to extensive use of remote sensing data and rover expeditions, significant domain knowledge has accumulated over the years about mineral composition of several regions of interest on Mars, which allow us to collect reliable labeled data required to train machine learning algorithms. In this study we demonstrate the utility of machine learning in two essential tasks for hyperspectral data analysis: nonlinear noise removal and mineral classification. We develop a simple yet effective hierarchical Bayesian model for estimating distributions of spectral patterns and extensively validate this model for mineral classification on several test images. Our results demonstrate that machine learning can be highly effective in exposing tiny outcrops of specific phases in orbital data that are not uncovered by traditional spectral analysis. We package implemented scripts, documentation illustrating use cases, and pixel-scale training data collected from dozens of well-characterized images into a new toolkit. We hope that this new toolkit will provide advanced and effective processing tools and improve community’s ability to map compositional units in remote sensing data quickly, accurately, and at scale.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Plebani2022machine</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Machine Learning Toolkit for {{CRISM}} Image Analysis}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Plebani, Emanuele and Ehlmann, Bethany L. and Leask, Ellen K. and Fox, Valerie K. and Dundar, M. Murat}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Icarus}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{376}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{114849}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0019-1035}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.icarus.2021.114849}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/textflow.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="textflow.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="karimi_textflow_2021" class="col-sm-8"> <div class="title">Textflow: Screenless Access to Non-Visual Smart Messaging</div> <div class="author"> <a href="https://www.linkedin.com/in/pegah-karimi-9194b4126" rel="external nofollow noopener" target="_blank">Pegah Karimi</a>, <em>Emanuele Plebani</em>, and <a href="https://luddy.iupui.edu/contact/profile/davide-bolchini" rel="external nofollow noopener" target="_blank">Davide Bolchini</a> </div> <div class="periodical"> <em>In Proceedings of the 26th International Conference on Intelligent User Interfaces</em>, Apr 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3397481.3450697" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/10.1145/3397481.3450697" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/Banus/Textflow" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Texting relies on screen-centric prompts designed for sighted users, still posing significant barriers to people who are blind and visually impaired (BVI). Can we re-imagine texting untethered from a visual display? In an interview study, 20 BVI adults shared situations surrounding their texting practices, recurrent topics of conversations, and challenges. Informed by these insights, we introduce TextFlow: a mixed-initiative context-aware system that generates entirely auditory message options relevant to the users’ location, activity, and time of the day. Users can browse and select suggested aural messages using finger-taps supported by an off-the-shelf finger-worn device, without having to hold or attend to a mobile screen. In an evaluative study, 10 BVI participants successfully interacted with TextFlow to browse and send messages in screen-free mode. The experiential response of the users shed light on the importance of bypassing the phone and accessing rapidly controllable messages at their fingertips while preserving privacy and accuracy with respect to speech or screen-based input. We discuss how non-visual access to proactive, contextual messaging can support the blind in a variety of daily scenarios.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">karimi_textflow_2021</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{{IUI} '21}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Textflow: {Screenless} {Access} to {Non}-{Visual} {Smart} {Messaging}}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-4503-8017-1}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3397481.3450697}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 26th {International} {Conference} on {Intelligent} {User} {Interfaces}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Karimi, Pegah and Plebani, Emanuele and Bolchini, Davide}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Text entry, Assistive technologies, Aural navigation, Intelligent wearable and mobile interfaces, Ubiquitous smart environments}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{186--196}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="tampouratzis_novel_2020" class="col-sm-8"> <div class="title">A Novel, Highly Integrated Simulator for Parallel and Distributed Systems</div> <div class="author"> <a href="https://ntampouratzis.com/" rel="external nofollow noopener" target="_blank">Nikolaos Tampouratzis</a>, Ioannis Papaefstathiou, <a href="https://www.linkedin.com/in/antonis-nikitakis-62544120" rel="external nofollow noopener" target="_blank">Antonios Nikitakis</a>, <a href="http://www.abrokalakis.gr/" rel="external nofollow noopener" target="_blank">Andreas Brokalakis</a>, Stamatis Andrianakis, Apostolos Dollas, <a href="https://marconlab.deib.polimi.it/" rel="external nofollow noopener" target="_blank">Marco Marcon</a>, and <em>Emanuele Plebani</em> </div> <div class="periodical"> <em>ACM Transactions on Architecture and Code Optimization</em>, Mar 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3378934" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/10.1145/3378934" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>In an era of complex networked parallel heterogeneous systems, simulating independently only parts, components, or attributes of a system-under-design is a cumbersome, inaccurate, and inefficient approach. Moreover, by considering each part of a system in an isolated manner, and due to the numerous and highly complicated interactions between the different components, the system optimization capabilities are severely limited. The presented fully-distributed simulation framework (called as COSSIM) is the first known open-source, high-performance simulator that can handle holistically system-of-systems including processors, peripherals and networks; such an approach is very appealing to both Cyber Physical Systems (CPS) and Highly Parallel Heterogeneous Systems designers and application developers. Our highly integrated approach is further augmented with accurate power estimation and security sub-tools that can tap on all system components and perform security and robustness analysis of the overall system under design—something that was unfeasible up to now. Additionally, a sophisticated Eclipse-based Graphical User Interface (GUI) has been developed to provide easy simulation setup, execution, and visualization of results. COSSIM has been evaluated when executing the widely used Netperf benchmark suite as well as a number of real-world applications. Final results demonstrate that the presented approach has up to 99% accuracy (when compared with the performance of the real system), while the overall simulation time can be accelerated almost linearly with the number of CPUs utilized by the simulator.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">tampouratzis_novel_2020</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A {Novel}, {Highly} {Integrated} {Simulator} for {Parallel} and {Distributed} {Systems}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1544-3566}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3378934}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Transactions on Architecture and Code Optimization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tampouratzis, Nikolaos and Papaefstathiou, Ioannis and Nikitakis, Antonios and Brokalakis, Andreas and Andrianakis, Stamatis and Dollas, Apostolos and Marcon, Marco and Plebani, Emanuele}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2:1--2:28}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Varenne2019Intelligent" class="col-sm-8"> <div class="title">Intelligent Recognition of TCP Intrusions for Embedded Micro-controllers</div> <div class="author"> Remi Varenne, Jean Michel Delorme, <em>Emanuele Plebani</em>, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, and <a href="https://www.linkedin.com/in/valeria-tomaselli-42460924" rel="external nofollow noopener" target="_blank">Valeria Tomaselli</a> </div> <div class="periodical"> <em>In International Conference on Image Analysis and Processing</em>, Mar 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-030-30754-7_36" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>IoT end-user devices are attractive and sometime easy targets for attackers, because they are often vulnerable in different aspects. Cyberattacks, started from those devices, can easily disrupt the availability of services offered by major internet companies. People that commonly get access to them across the world may experience abrupt interruption of services they use. In that context, this paper describes an embedded prototype to classify intrusions, affecting TCP packets. The proposed solution adopts an Artificial Neural Network (ANN) executed on resource-constrained and low-cost embedded micro controllers. The prototype operates without the need of remote intelligence assist. The adoption of an on-the-edge artificial intelligence architecture brings advantages such as responsiveness, promptness and low power consumption. The embedded intelligence is trained by using the well-known KDD Cup 1999 dataset, properly balanced on 5 types of labelled intrusions patterns. A pre-trained ANN classifies features extracted from TCP packets. The results achieved in this paper refer to the application running on the low cost widely available Nucleo STM32 micro controller boards from STMicroelectronics, featuring a F3 chip running at 72 MHz and a F4 chip running at 84 MHz with small embedded RAM and Flash memory.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Varenne2019Intelligent</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Intelligent {{Recognition}} of {{TCP Intrusions}} for {{Embedded Micro-controllers}}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International {{Conference}} on {{Image Analysis}} and {{Processing}}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Varenne, Remi and Delorme, Jean Michel and Plebani, Emanuele and Pau, Danilo and Tomaselli, Valeria}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11808 LNCS}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{361--373}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer Verlag}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Trento}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{16113349}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-30754-7_36}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-030-30753-0}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Brokalakis2018COSSIM" class="col-sm-8"> <div class="title">COSSIM: An Open-Source Integrated Solution to Address the Simulator Gap for Systems of Systems</div> <div class="author"> <a href="http://www.abrokalakis.gr/" rel="external nofollow noopener" target="_blank">Andreas Brokalakis</a>, <a href="https://ntampouratzis.com/" rel="external nofollow noopener" target="_blank">Nikolaos Tampouratzis</a>, <a href="https://www.linkedin.com/in/antonis-nikitakis-62544120" rel="external nofollow noopener" target="_blank">Antonios Nikitakis</a>, Ioannis Papaefstathiou, Stamatis Andrianakis, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, <em>Emanuele Plebani</em>, <a href="https://www.linkedin.com/in/marco-brando-paracchini" rel="external nofollow noopener" target="_blank">Marco Paracchini</a>, <a href="https://marconlab.deib.polimi.it/" rel="external nofollow noopener" target="_blank">Marco Marcon</a>, Ioannis Sourdis, Prajith Ramakrishnan Geethakumari, Maria Carmen Palacios, Miguel Angel Anton, and Attila Szasz </div> <div class="periodical"> <em>In 2018 21st Euromicro Conference on Digital System Design (DSD)</em>, Aug 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/DSD.2018.00033" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/8491804" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>In an era of complex networked heterogeneous systems, simulating independently only parts, components or attributes of a system under design is not a viable, accurate or efficient option. The interactions are too many and too complicated to produce meaningful results and the optimization opportunities are severely limited when considering each part of a system in an isolated manner. The presented COSSIM simulation framework is the first known open-source, high-performance simulator that can handle holistically system-of-systems including processors, peripherals and networks; such an approach is very appealing to both CPS/IoT and Highly Parallel Heterogeneous Systems designers and application developers. Our highly integrated approach is further augmented with accurate power estimation and security sub-tools that can tap on all system components and perform security and robustness analysis of the overall networked system. Additionally, a GUI has been developed to provide easy simulation set-up, execution and visualization of results. COSSIM has been evaluated using real-world applications representing cloud (mobile visual search) and CPS systems (building management) demonstrating high accuracy and performance that scales almost linearly with the number of CPUs dedicated to the simulator.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Brokalakis2018COSSIM</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{{COSSIM}}: {{An Open-Source Integrated Solution}} to {{Address}} the {{Simulator Gap}} for {{Systems}} of {{Systems}}}</span><span class="p">,</span>
  <span class="na">shorttitle</span> <span class="p">=</span> <span class="s">{{{COSSIM}}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2018 21st {{Euromicro Conference}} on {{Digital System Design}} ({{DSD}})}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Brokalakis, Andreas and Tampouratzis, Nikolaos and Nikitakis, Antonios and Papaefstathiou, Ioannis and Andrianakis, Stamatis and Pau, Danilo and Plebani, Emanuele and Paracchini, Marco and Marcon, Marco and Sourdis, Ioannis and Geethakumari, Prajith Ramakrishnan and Palacios, Maria Carmen and Anton, Miguel Angel and Szasz, Attila}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{115--120}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/DSD.2018.00033}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Brokalakis2018opensource" class="col-sm-8"> <div class="title">An Open-Source Extendable, Highly-Accurate and Security Aware Simulator for Cloud Applications</div> <div class="author"> <a href="http://www.abrokalakis.gr/" rel="external nofollow noopener" target="_blank">Andreas Brokalakis</a>, <a href="https://ntampouratzis.com/" rel="external nofollow noopener" target="_blank">Nikolaos Tampouratzis</a>, <a href="https://www.linkedin.com/in/antonis-nikitakis-62544120" rel="external nofollow noopener" target="_blank">Antonios Nikitakis</a>, Ioannis Papaefstathiou, Stamatis Andrianakis, Apostolos Dollas, <a href="https://www.linkedin.com/in/marco-brando-paracchini" rel="external nofollow noopener" target="_blank">Marco Paracchini</a>, <a href="https://marconlab.deib.polimi.it/" rel="external nofollow noopener" target="_blank">Marco Marcon</a>, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pietro Pau</a>, and <em>Emanuele Plebani</em> </div> <div class="periodical"> <em>21st Conference on Innovation in Clouds, Internet and Networks, ICIN 2018</em>, Aug 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ICIN.2018.8401578" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>In this demo, we present COSSIM, an open-source simulation framework for cloud applications. Our solution models the client and server computing devices as well as the network that comprise the overall system and thus provides cycle accurate results, realistic communications and power/energy consumption estimates based on the actual dynamic usage scenarios. The simulator provides the necessary hooks to security testing software and can be extended through an IEEE standardized interface to include additional tools, such as simulators of physical models. The application that will be used to demonstrate COSSIM is mobile visual search, where mobile nodes capture images, extract their compressed representation and dispatch a query to the cloud. A server compares the received query to a local database and sends back some of the corresponding results.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Brokalakis2018opensource</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Open-Source Extendable, Highly-Accurate and Security Aware Simulator for Cloud Applications}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Brokalakis, Andreas and Tampouratzis, Nikolaos and Nikitakis, Antonios and Papaefstathiou, Ioannis and Andrianakis, Stamatis and Dollas, Apostolos and Paracchini, Marco and Marcon, Marco and Pau, Danilo Pietro and Plebani, Emanuele}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{21st Conference on Innovation in Clouds, Internet and Networks, ICIN 2018}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--3}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2472-8144}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICIN.2018.8401578}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781538634585}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Carcano2018Pretrainable" class="col-sm-8"> <div class="title">Pre-Trainable Reservoir Computing with Recursive Neural Gas</div> <div class="author"> Luca Carcano, <em>Emanuele Plebani</em>, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pietro Pau</a>, and Marco Piastra </div> <div class="periodical"> <em></em> Jul 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/1807.09510" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Echo State Networks (ESN) are a class of Recurrent Neural Networks (RNN) that has gained substantial popularity due to their effectiveness, ease of use and potential for compact hardware implementation. An ESN contains the three network layers input, reservoir and readout where the reservoir is the truly recurrent network. The input and reservoir layers of an ESN are initialized at random and never trained afterwards and the training of the ESN is applied to the readout layer only. The alternative of Recursive Neural Gas (RNG) is one of the many proposals of fully-trainable reservoirs that can be found in the literature. Although some improvements in performance have been reported with RNG, to the best of authors’ knowledge, no experimental comparative results are known with benchmarks for which ESN is known to yield excellent results. This work describes an accurate model of RNG together with some extensions to the models presented in the literature and shows comparative results on three well-known and accepted datasets. The experimental results obtained show that, under specific circumstances, RNG-based reservoirs can achieve better performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Carcano2018Pretrainable</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pre-Trainable {{Reservoir Computing}} with {{Recursive Neural Gas}}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Carcano, Luca and Plebani, Emanuele and Pau, Danilo Pietro and Piastra, Marco}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Cunial2018Parallelized" class="col-sm-8"> <div class="title">Parallelized Convolutions for Embedded Ultra Low Power Deep Learning SoC</div> <div class="author"> Lorenzo Cunial, Ahmet Erdem, <a href="https://silvano.faculty.polimi.it/" rel="external nofollow noopener" target="_blank">Cristina Silvano</a>, <a href="https://www.linkedin.com/in/mirko-falchetto-5786691" rel="external nofollow noopener" target="_blank">Mirko Falchetto</a>, <a href="https://www.linkedin.com/in/andreaornstein" rel="external nofollow noopener" target="_blank">Andrea C. Ornstein</a>, <em>Emanuele Plebani</em>, <a href="https://www.linkedin.com/in/giuseppe-desoli-09b690" rel="external nofollow noopener" target="_blank">Giuseppe Desoli</a>, and <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a> </div> <div class="periodical"> <em>In IEEE 4th International Forum on Research and Technologies for Society and Industry, RTSI 2018 - Proceedings</em>, Nov 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/RTSI.2018.8548362" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Deep Convolutional Neural Networks (DCNNs) achieve state of the art results compared to classic machine learning in many applications that need recognition, identification and classification. An ever-increasing embedded deployment of DCNNs inference engines thus supporting the intelligence close to the sensor paradigm has been observed, overcoming limitations of cloud-based computing as bandwidth requirements, security, privacy, scalability, and responsiveness. However, increasing the robustness and accuracy of DCNNs comes at the price of increased computational cost. As result, implementing CNNs on embedded devices with real-time constraints is a challenge if the lowest power consumption shall be achieved. A solution to the challenge is to take advantage of the intra-device massive fine grain parallelism offered by these systems and benefit from the extensive concurrency exhibited by DCNN processing pipelines. The trick is to divide intensive tasks into smaller, weakly interacting batches subject to parallel processing. Referred to that, this paper has mainly two goals: 1) describe the implementation of a state-of-art technique to map DCNN most intensive tasks (dominated by multiply-and-accumulate ops) onto Orlando SoC, an ultra-low power heterogeneous multi cores developed by STMicroelectronics; 2) integrate the proposed implementation on a toolchain that allows deep learning developers to deploy DCNNs on low-power applications.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Cunial2018Parallelized</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Parallelized {{Convolutions}} for {{Embedded Ultra Low Power Deep Learning SoC}}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{{IEEE}} 4th {{International Forum}} on {{Research}} and {{Technologies}} for {{Society}} and {{Industry}}, {{RTSI}} 2018 - {{Proceedings}}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cunial, Lorenzo and Erdem, Ahmet and Silvano, Cristina and Falchetto, Mirko and Ornstein, Andrea C. and Plebani, Emanuele and Desoli, Giuseppe and Pau, Danilo}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{Institute of Electrical and Electronics Engineers Inc.}}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/RTSI.2018.8548362}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-5386-6282-3}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="DeVita2018Lowpower" class="col-sm-8"> <div class="title">Low-Power Design of a Gravity Rotation Module for HAR Systems Based on Inertial Sensors</div> <div class="author"> Antonio De Vita, <a href="https://docenti.unisa.it/020369/home" rel="external nofollow noopener" target="_blank">Gian Domenico Licciardo</a>, Luigi Di Benedetto, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, <em>Emanuele Plebani</em>, and <a href="https://www.linkedin.com/in/angelobosco" rel="external nofollow noopener" target="_blank">Angelo Bosco</a> </div> <div class="periodical"> <em>Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors</em>, Nov 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ASAP.2018.8445130" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>In this paper, for the first time the design of a HW module to eliminate the effect of the gravity acceleration from data acquired from inertial sensors is presented. A new ’hardware friendly’ algorithm has been derived from the Rodrigues’ rotation formula, which can be implemented in a more compact iterative structure. By exploiting 32-bit floating-point arithmetic, the design is able to combine high accuracy and low power requirements needed by any intelligent Human Activity Recognition system, based on artificial neural networks. Synthesis with 65 nm CMOS std cells returns a power dissipation below 2 \(μ\)W and an area of about 0.05 mm2, Results are the current state-of-the-art for this kind of system and they are very promising for the future integration in smart sensors for wearable applications.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DeVita2018Lowpower</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Low-Power {{Design}} of a {{Gravity Rotation Module}} for {{HAR Systems Based}} on {{Inertial Sensors}}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{De Vita, Antonio and Licciardo, Gian Domenico and Di Benedetto, Luigi and Pau, Danilo and Plebani, Emanuele and Bosco, Angelo}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2018-July}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--4}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{10636862}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ASAP.2018.8445130}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781538674796}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Nicosia2018Efficient" class="col-sm-8"> <div class="title">Efficient Light Harvesting for Accurate Neural Classification of Human Activities</div> <div class="author"> Alessandro Nicosia, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, Davide Giacalone, <em>Emanuele Plebani</em>, <a href="https://www.linkedin.com/in/angelobosco" rel="external nofollow noopener" target="_blank">Angelo Bosco</a>, and Antonio Iacchetti </div> <div class="periodical"> <em>2018 IEEE International Conference on Consumer Electronics, ICCE 2018</em>, Nov 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ICCE.2018.8326103" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Energy autonomy extension of wearable devices is an ever increasing user need and it can be achieved by inexpensive energy harvesting from the broadly available solar and artificial light. However efficient conversion, relevant storage and utilization must be carefully implemented if the device supports power-hungry applications such as Artificial Intelligence for human activity classification based on Artificial Neural Networks. In this paper, a whole hardware and software system implementation is presented, which is able to achieve system autonomy extension and at the same time high classification accuracy. Quantitative and qualitative results are shown under real working conditions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Nicosia2018Efficient</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficient Light Harvesting for Accurate Neural Classification of Human Activities}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nicosia, Alessandro and Pau, Danilo and Giacalone, Davide and Plebani, Emanuele and Bosco, Angelo and Iacchetti, Antonio}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{2018 IEEE International Conference on Consumer Electronics, ICCE 2018}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2018-Janua}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--4}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICCE.2018.8326103}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781538630259}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Ranalli2018Automated" class="col-sm-8"> <div class="title">Automated Generation of a Single Shot Detector C Library from High Level Deep Learning Frameworks</div> <div class="author"> <a href="https://www.linkedin.com/in/luca-ranalli-417322151" rel="external nofollow noopener" target="_blank">Luca Ranalli</a>, <a href="https://www.unibo.it/sitoweb/luigi.distefano/en" rel="external nofollow noopener" target="_blank">Luigi Di Stefano</a>, <em>Emanuele Plebani</em>, <a href="https://www.linkedin.com/in/mirko-falchetto-5786691" rel="external nofollow noopener" target="_blank">Mirko Falchetto</a>, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, and Viviana D’Alto </div> <div class="periodical"> <em>In IEEE 4th International Forum on Research and Technologies for Society and Industry, RTSI 2018 - Proceedings</em>, Nov 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/RTSI.2018.8548427" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>In designing accurate and high-performance artificial neural networks (ANN) topologies for embedded systems, several weeks of engineering work are required to properly condition the input data, implement architectures optimized both in term of memory and operations using any of the off-the-shelf deep learning frameworks and then test the models in proper-scale data driven experiments. Moreover, code implementing the layers needs to be mapped and validated on the target systems, requiring additional months of hard and hand-made engineering work. To shorten this inefficient and un-productive development procedure, an efficient and automated C library generation workflow has been created. This work presents the phases involved in the automated mapping of a Single Shot Object Detector (SSD) model on an embedded library, where low power consumption is the focus and memory usage needs to be properly handled and minimized when possible. The implementation aspects, dealing with the mapping of high-level functions and dynamic data structures into low-level logical equivalents in ANSI C are presented; in addition, a brief explanation of the validation process as well as a short summary on the link between memory usage and the implementations details of the detector are also provided.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Ranalli2018Automated</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automated {{Generation}} of a {{Single Shot Detector C Library}} from {{High Level Deep Learning Frameworks}}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{{IEEE}} 4th {{International Forum}} on {{Research}} and {{Technologies}} for {{Society}} and {{Industry}}, {{RTSI}} 2018 - {{Proceedings}}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ranalli, Luca and Di Stefano, Luigi and Plebani, Emanuele and Falchetto, Mirko and Pau, Danilo and D'Alto, Viviana}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{Institute of Electrical and Electronics Engineers Inc.}}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/RTSI.2018.8548427}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-5386-6282-3}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Shahnawaz2018Studying" class="col-sm-8"> <div class="title">Studying the Effects of Feature Extraction Settings on the Accuracy and Memory Requirements of Neural Networks for Keyword Spotting</div> <div class="author"> <a href="https://www.linkedin.com/in/muhammad-shahnawaz" rel="external nofollow noopener" target="_blank">Muhammad Shahnawaz</a>, <em>Emanuele Plebani</em>, Ivana Guaneri, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, and <a href="https://marconlab.deib.polimi.it/" rel="external nofollow noopener" target="_blank">Marco Marcon</a> </div> <div class="periodical"> <em>In IEEE International Conference on Consumer Electronics - Berlin, ICCE-Berlin</em>, Dec 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ICCE-Berlin.2018.8576243" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Due to the always-on nature of keyword spotting (KWS) systems, low power consumption micro-controller units (MCU) are the best choices as deployment devices. However, small computation power and memory budget of MCUs can harm the accuracy requirements. Although, many studies have been conducted to design small memory footprint neural networks to address this problem, the effects of different feature extraction settings are rarely studied. This work addresses this important question by first, comparing six of the most popular and state of the art neural network architectures for KWS on the Google Speech-Commands dataset. Then, keeping the network architectures unchanged it performs comprehensive investigations on the effects of different frequency transformation settings, such as number of used mel-frequency cepstrum coefficients (MFCCs) and length of the stride window, on the accuracy and memory footprint (RAM/ROM) of the models. The results show different preprocessing settings can change the accuracy and RAM/ROM requirements significantly of the models. Furthermore, it is shown that DS-CNN outperforms the other architectures in terms of accuracy with a value of 93.47% with least amount of ROM requirements, while the GRU outperforms all other networks with an accuracy of 91.02% with smallest RAM requirements.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Shahnawaz2018Studying</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Studying the Effects of Feature Extraction Settings on the Accuracy and Memory Requirements of Neural Networks for Keyword Spotting}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{{IEEE International Conference}} on {{Consumer Electronics}} - {{Berlin}}, {{ICCE-Berlin}}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shahnawaz, Muhammad and Plebani, Emanuele and Guaneri, Ivana and Pau, Danilo and Marcon, Marco}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2018-Septe}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE Computer Society}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{21666822}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICCE-Berlin.2018.8576243}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-5386-6095-9}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Marasco2017Enhancement" class="col-sm-8"> <div class="title">Towards Enhancement of Gender Estimation from Fingerprints</div> <div class="author"> <a href="https://sites.google.com/view/emanuelamarasco/" rel="external nofollow noopener" target="_blank">Emanuela Marasco</a>, <em>Emanuele Plebani</em>, <a href="https://www.linkedin.com/in/daogiang" rel="external nofollow noopener" target="_blank">Giang Dao</a>, and Bojan Cukic </div> <div class="periodical"> <em>In IEEE International Workshop on The Bright and Dark Sides of Computer Vision: Challenges and Opportunities for Privacy and Security (CV-COPS )</em>, Dec 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Accurate gender prediction brings benefit to several applications. In biometrics, beyond filtering large databases, a gender recognizer can be combined with the output of primary identifiers to increase the recognition accuracy in challenging scenarios (e.g., partial evidence) [1]. In criminal investigation, gender classification may minimize the list of suspects. Although the development of reliable gender estimators is needed, most of the existing approaches are not highly accurate, and often the process is not fully automated. Epidermal ridges are formed during the first three / four months of the gestational period and the resulting ridge configuration remains stable. Ridges and their arrangement, referred to as dermatoglyphics, are determined not only based on environmental factors but also on genetics [2, 3]. In the scientific literature, fingerprints of females are assumed to have thinner epidermal ridge details which leads females having a higher ridge density compared to males. Subsequently, existing methods tend to relate gender determination to a direct measure of the ridge density [4]. However, this approach may not be robust to image degradation (e.g., partial impressions, low quality).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Marasco2017Enhancement</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards {{Enhancement}} of {{Gender Estimation}} from {{Fingerprints}}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{{IEEE International Workshop}} on {{The Bright}} and {{Dark Sides}} of {{Computer Vision}}: {{Challenges}} and {{Opportunities}} for {{Privacy}} and {{Security}} ({{CV-COPS}} )}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Marasco, Emanuela and Plebani, Emanuele and Dao, Giang and Cukic, Bojan}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--2}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Honolulu, Hawaii}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Martino2017Accurate" class="col-sm-8"> <div class="title">Accurate Cyber-Physical System Simulation for Distributed Visual Search Applications</div> <div class="author"> <a href="https://www.linkedin.com/in/danilo-maria-martino-479303188" rel="external nofollow noopener" target="_blank">Danilo Martino</a>, Yun Shen, <a href="https://www.linkedin.com/in/marco-brando-paracchini" rel="external nofollow noopener" target="_blank">Marco Paracchini</a>, <a href="https://marconlab.deib.polimi.it/" rel="external nofollow noopener" target="_blank">Marco Marcon</a>, <em>Emanuele Plebani</em>, and <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pietro Pau</a> </div> <div class="periodical"> <em>In 2017 IEEE 3rd International Forum on Research and Technologies for Society and Industry (RTSI)</em>, Sep 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/RTSI.2017.8065917" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/document/8065917/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>A Cyber-Physical System (CPS) is defined as a, usually distributed, system that links the digital (cyber) and physical world. They feature different computational cores and heterogeneous sensors linked through networks of different types allowing a deeper interaction with the physical world, collecting, storing and exchanging information intelligently. In this work, an open source CPS simulator called COSSIM is described and a smart mechanism is proposed in order to turn it into a co-simulator. In addition to this, a CPS based on a Computer Vision application, called Mobile Visual Search (MVS), is described and ported to COSSIM in order to test the correctness of the simulation and to prove the benefit of the proposed acceleration. Quantitative and qualitative precision results in both real and simulated scenarios are also presented.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Martino2017Accurate</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Accurate Cyber-Physical System Simulation for Distributed Visual Search Applications}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2017 {{IEEE}} 3rd {{International Forum}} on {{Research}} and {{Technologies}} for {{Society}} and {{Industry}} ({{RTSI}})}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Martino, Danilo and Shen, Yun and Paracchini, Marco and Marcon, Marco and Plebani, Emanuele and Pau, Danilo Pietro}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--5}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Modena}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/RTSI.2017.8065917}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-5386-3906-1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Paracchini2017" class="col-sm-8"> <div class="title">Embedded Real-Time Visual Search with Visual Distance Estimation</div> <div class="author"> <a href="https://www.linkedin.com/in/marco-brando-paracchini" rel="external nofollow noopener" target="_blank">Marco Paracchini</a>, <em>Emanuele Plebani</em>, Mehdi Ben Iche, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pietro Pau</a>, and <a href="https://marconlab.deib.polimi.it/" rel="external nofollow noopener" target="_blank">Marco Marcon</a> </div> <div class="periodical"> <em>In ICIAP</em>, Sep 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-319-68548-9_6" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1007/978-3-319-68548-9_6" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Visual Search algorithms are a class of methods that retrieve images by their content. In particular, given a database of reference images and a query image the goal is to find an image among the database that depicts the same object as in the query, if any. Moreover, in many different real case applications more than one object of interest could be viewed in the query image. Furthermore, in this kind of situations, often, it is not sufficient to identify the object depicted on a query image but its precise localization inside the scene viewed by the camera is also requested. In this paper we propose to couple a Visual Search system, which can retrieve multiple objects from the same query image, with an additional Distance Estimation module that exploits the localization information already computed inside the Visual Search stage to estimate localization of the object in three dimensions. In this work we implement the complete image retrieval and spatial localization pipeline (including relative distance estimation) on two different embedded devices, exploiting also their GPU in order to get near real time performances on low-power devices. Lastly, the accuracy of the proposed distance estimation is evaluated on a dataset of annotated query-reference pairs ad-hoc created.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Paracchini2017</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Embedded {{Real-Time Visual Search}} with {{Visual Distance Estimation}}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{{ICIAP}}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Paracchini, Marco and Plebani, Emanuele and Iche, Mehdi Ben and Pau, Danilo Pietro and Marcon, Marco}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Battiato, Sebastiano and Gallo, Giovanni and Schettini, Raimondo and Stanco, Filippo}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{59--69}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer International Publishing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Catania, Italy}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-68548-9_6}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-319-68548-9}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Tomaselli2017" class="col-sm-8"> <div class="title">Complexity and Accuracy of Hand-Crafted Detection Methods Compared to Convolutional Neural Networks</div> <div class="author"> <a href="https://www.linkedin.com/in/valeria-tomaselli-42460924" rel="external nofollow noopener" target="_blank">Valeria Tomaselli</a>, <em>Emanuele Plebani</em>, Mauro Strano, and <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a> </div> <div class="periodical"> <em>In ICIAP</em>, Sep 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-319-68560-1_27" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1007/978-3-319-68560-1_27" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Even though Convolutional Neural Networks have had the best accuracy in the last few years, they have a price in term of computational complexity and memory footprint, due to a large number of multiply-accumulate operations and model parameters. For embedded systems, this complexity severely limits the opportunities to reduce power consumption, which is dominated by memory read and write operations. Anticipating the oncoming integration into intelligent sensor devices, we compare hand-crafted features for the detection of a limited number of objects against some typical convolutional neural network architectures. Experiments on some state-of-the-art datasets, addressing detection tasks, show that for some problems the increased complexity of neural networks is not reflected by a large increase in accuracy. Moreover, our analysis suggests that for embedded devices hand-crafted features are still competitive in terms of accuracy/complexity trade-offs.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Tomaselli2017</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Complexity and {{Accuracy}} of {{Hand-Crafted Detection Methods Compared}} to {{Convolutional Neural Networks}}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{{ICIAP}}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tomaselli, Valeria and Plebani, Emanuele and Strano, Mauro and Pau, Danilo}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Battiato, Sebastiano and Gallo, Giovanni and Schettini, Raimondo and Stanco, Filippo}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{298--308}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer International Publishing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Catania, Italy}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-68560-1_27}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-319-68560-1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Desoli2016" class="col-sm-8"> <div class="title">The Orlando Project: A 28 Nm FD-SOI Low Memory Embedded Neural Network ASIC</div> <div class="author"> <a href="https://www.linkedin.com/in/giuseppe-desoli-09b690" rel="external nofollow noopener" target="_blank">Giuseppe Desoli</a>, <a href="https://www.linkedin.com/in/valeria-tomaselli-42460924" rel="external nofollow noopener" target="_blank">Valeria Tomaselli</a>, <em>Emanuele Plebani</em>, <a href="https://www.linkedin.com/in/giulio-urlini-pmp%C2%AE-4053835" rel="external nofollow noopener" target="_blank">Giulio Urlini</a>, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, Viviana D’Alto, <a href="https://www.linkedin.com/in/tommaso-majo-a835a56" rel="external nofollow noopener" target="_blank">Tommaso Majo</a>, <a href="https://www.linkedin.com/in/fabiodeambroggi" rel="external nofollow noopener" target="_blank">Fabio De Ambroggi</a>, <a href="https://www.linkedin.com/in/andreas-boesch-0b0b0b" rel="external nofollow noopener" target="_blank">Thomas Boesch</a>, <a href="https://www.researchgate.net/profile/Surinder-Singh-9" rel="external nofollow noopener" target="_blank">Surinder-pal Singh</a>, Elio Guidetti, and Nitin Chawla </div> <div class="periodical"> <em>In Advanced Concepts for Intelligent Vision Systems</em>, Sep 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-319-48680-2_20" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://link.springer.com/10.1007/978-3-319-48680-2_20" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>The recent success of neural networks in various computer vision tasks open the possibility to add visual intelligence to mobile and wearable devices; however, the stringent power requirements are unsuitable for networks run on embedded CPUs or GPUs. To address such challenges, STMicroelectronics developed the Orlando Project, a new and low power architecture for convolutional neural network acceleration suited for wearable devices. An important contribution to the energy usage is the storage and access to the neural network parameters. In this paper, we show that with adequate model compression schemes based on weight quantization and pruning, a whole AlexNet network can fit in the local memory of an embedded processor, thus avoiding additional system complexity and energy usage, with no or low impact on the accuracy of the network. Moreover, the compression methods work well across different tasks, e.g. image classification and object detection.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Desoli2016</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The {{Orlando Project}}: {{A}} 28~Nm {{FD-SOI Low Memory Embedded Neural Network ASIC}}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advanced {{Concepts}} for {{Intelligent Vision Systems}}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Desoli, Giuseppe and Tomaselli, Valeria and Plebani, Emanuele and Urlini, Giulio and Pau, Danilo and D'Alto, Viviana and Majo, Tommaso and De Ambroggi, Fabio and Boesch, Thomas and Singh, Surinder-pal and Guidetti, Elio and Chawla, Nitin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{217--227}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer International Publishing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Lecce, Italy}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-48680-2_20}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Paracchini2016" class="col-sm-8"> <div class="title">Accurate Omnidirectional Multi-Camera Embedded Structure from Motion</div> <div class="author"> <a href="https://www.linkedin.com/in/marco-brando-paracchini" rel="external nofollow noopener" target="_blank">Marco Paracchini</a>, <a href="https://www.linkedin.com/in/angelo-schepis-1ba310142" rel="external nofollow noopener" target="_blank">Angelo Schepis</a>, <a href="https://marconlab.deib.polimi.it/" rel="external nofollow noopener" target="_blank">Marco Marcon</a>, <a href="https://www.linkedin.com/in/mirko-falchetto-5786691" rel="external nofollow noopener" target="_blank">Mirko Falchetto</a>, <em>Emanuele Plebani</em>, and <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a> </div> <div class="periodical"> <em>In Research and Technologies for Society and Industry Leveraging a Better Tomorrow (RTSI), 2016 IEEE 2nd International Forum On</em>, Sep 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/RTSI.2016.7740560" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/document/7740560/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Trajectory estimation and 3D scene reconstruction from multiple cameras (also referred as Structure from Motion, SfM) will have a central role in the future of automotive industry. Typical appliance fields will be: autonomous navigation/guidance, collisions avoidance against static or moving objects (in particular pedestrians), parking assisted maneuvers and many more. The work exposed in this paper had mainly two different goals: (1) to describe the implementation of a real time embedded SfM modular pipeline featuring a dedicated optimized HW/SW system partitioning. It included also nonlinear optimizations such as local and global bundle adjustment at different stages of the pipeline; (2) to demonstrate quantitatively its performances on a synthetic test space specifically designed for its characterization. In order to make the system reliable and effective, providing the driver or the autonomous vehicle with a prompt response, the data rates and low latency of the 5G communication systems appear to make this choice the most promising communication solution.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Paracchini2016</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Accurate Omnidirectional Multi-Camera Embedded Structure from Motion}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Research and {{Technologies}} for {{Society}} and {{Industry Leveraging}} a Better Tomorrow ({{RTSI}}), 2016 {{IEEE}} 2nd {{International Forum}} On}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Paracchini, Marco and Schepis, Angelo and Marcon, Marco and Falchetto, Mirko and Plebani, Emanuele and Pau, Danilo}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--6}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/RTSI.2016.7740560}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-5090-1131-5}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="paracchini2016visual" class="col-sm-8"> <div class="title">Visual Search of Multiple Objects from a Single Query</div> <div class="author"> <a href="https://www.linkedin.com/in/marco-brando-paracchini" rel="external nofollow noopener" target="_blank">Marco Paracchini</a>, <a href="https://marconlab.deib.polimi.it/" rel="external nofollow noopener" target="_blank">Marco Marcon</a>, <em>Emanuele Plebani</em>, and <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pietro Pau</a> </div> <div class="periodical"> <em>In Consumer Electronics-Berlin (ICCE-Berlin), 2016 IEEE 6th International Conference On</em>, Sep 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ICCE-Berlin.2016.7684712" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/abstract/document/7684712/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Hundreds of millions of images are uploaded to the cloud every day. Innovative applications able to analyze and extract efficiently information from such a big database are needed nowadays more than ever. Visual Search is an application able to retrieve information of a query image comparing it against a large image database. In this paper a Visual Search pipeline implementation is presented able to retrieve multiple objects depicted in a single query image. Quantitative and qualitative precision results are shown on both real and synthetic datasets.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">paracchini2016visual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Visual {{Search}} of Multiple Objects from a Single Query}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Consumer {{Electronics-Berlin}} ({{ICCE-Berlin}}), 2016 {{IEEE}} 6th {{International Conference}} On}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Paracchini, Marco and Marcon, Marco and Plebani, Emanuele and Pau, Danilo Pietro}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{41--45}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Berlin, Germany}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICCE-Berlin.2016.7684712}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="tome2016reduced" class="col-sm-8"> <div class="title">Reduced Memory Region Based Deep Convolutional Neural Network Detection</div> <div class="author"> <a href="https://denistome.github.io/" rel="external nofollow noopener" target="_blank">Denis Tomé</a>, <a href="https://www.linkedin.com/in/luca-bondi" rel="external nofollow noopener" target="_blank">Luca Bondi</a>, <em>Emanuele Plebani</em>, <a href="https://www.linkedin.com/in/luca-baroffio-6942849a" rel="external nofollow noopener" target="_blank">Luca Baroffio</a>, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, and <a href="https://tubaro.faculty.polimi.it/" rel="external nofollow noopener" target="_blank">Stefano Tubaro</a> </div> <div class="periodical"> <em>In Consumer Electronics-Berlin (ICCE-Berlin), 2016 IEEE 6th International Conference On</em>, Sep 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ICCE-Berlin.2016.7684706" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/1609.02500" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/7684706" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Accurate pedestrian detection has a primary role in automotive safety: for example, by issuing warnings to the driver or acting actively on car’s brakes, it helps decreasing the probability of injuries and human fatalities. In order to achieve very high accuracy, recent pedestrian detectors have been based on Convolutional Neural Networks (CNN). Unfortunately, such approaches require vast amounts of computational power and memory, preventing efficient implementations on embedded systems. This work proposes a CNN-based detector, adapting a general-purpose convolutional network to the task at hand. By thoroughly analyzing and optimizing each step of the detection pipeline, we develop an architecture that outperforms methods based on traditional image features and achieves an accuracy close to the state-of-the-art while having low computational complexity. Furthermore, the model is compressed in order to fit the tight constrains of low power devices with a limited amount of embedded memory available. This paper makes two main contributions: (1) it proves that a region based deep neural network can be finely tuned to achieve adequate accuracy for pedestrian detection (2) it achieves a very low memory usage without reducing detection accuracy on the Caltech Pedestrian dataset.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">tome2016reduced</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Reduced {{Memory Region Based Deep Convolutional Neural Network Detection}}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Consumer {{Electronics-Berlin}} ({{ICCE-Berlin}}), 2016 {{IEEE}} 6th {{International Conference}} On}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tomé, Denis and Bondi, Luca and Plebani, Emanuele and Baroffio, Luca and Pau, Danilo and Tubaro, Stefano}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{15--19}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Berlin, Germany}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICCE-Berlin.2016.7684706}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Paracchini2015" class="col-sm-8"> <div class="title">Accurate Characterization of Embedded Structure from Motion</div> <div class="author"> <a href="https://www.linkedin.com/in/marco-brando-paracchini" rel="external nofollow noopener" target="_blank">Marco Brando Paracchini</a>, <a href="https://marconlab.deib.polimi.it/" rel="external nofollow noopener" target="_blank">Marco Marcon</a>, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, <a href="https://www.linkedin.com/in/mirko-falchetto-5786691" rel="external nofollow noopener" target="_blank">Mirko Falchetto</a>, and <em>Emanuele Plebani</em> </div> <div class="periodical"> <em>In 2015 IEEE 1st International Workshop on Consumer Electronics (CE WS)</em>, Mar 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/CEWS.2015.7867140" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/document/7867140/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Trajectory estimation and 3d scene reconstruction from single camera, e.g. Structure from Motion, is going to have a central role in the future of automotive industry. Typical appliance fields will be: collisions avoidance with any kind of object (people included), parking assisted maneuvers and many more. Indeed various countries are becoming more and more concerned about road traffic safety and therefore through its “Advanced Program”, EuroNCAP rewards vehicle manufacturers who employ Advanced Safety Technologies that assists the driver. This paper had mainly two different goals: (1) to describe the implementation of a state of art Structure from Motion pipeline able to run in real time with embedded fish-eye camera, which includes nonlinear optimization (i.e. local bundle adjustment); (2) to demonstrate quantitatively its performances on a synthetic test space specifically designed for its characterization in term of accuracy.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Paracchini2015</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Accurate Characterization of Embedded {{Structure}} from {{Motion}}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2015 {{IEEE}} 1st {{International Workshop}} on {{Consumer Electronics}} ({{CE WS}})}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Paracchini, Marco Brando and Marcon, Marco and Pau, Danilo and Falchetto, Mirko and Plebani, Emanuele}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5--8}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CEWS.2015.7867140}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-5090-4268-5}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Petrelli2015a" class="col-sm-8"> <div class="title">RGB-D Visual Search with Compact Binary Codes</div> <div class="author"> <a href="https://www.linkedin.com/in/alioscia-petrelli-851a3b4" rel="external nofollow noopener" target="_blank">Alioscia Petrelli</a>, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, <em>Emanuele Plebani</em>, and <a href="https://www.unibo.it/sitoweb/luigi.distefano/en" rel="external nofollow noopener" target="_blank">Luigi Di Stefano</a> </div> <div class="periodical"> <em>In 2015 International Conference on 3D Vision</em>, Mar 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/3DV.2015.17" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=7335472" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>As integration of depth sensing into mobile devices is likely forthcoming, we investigate on merging appearance and shape information for mobile visual search. Accordingly, we propose an RGB-D search engine architecture that can attain high recognition rates with peculiarly moderate bandwidth requirements. Our experiments include a comparison to the CDVS (Compact Descriptors for Visual Search) pipeline, candidate to become part of the MPEG-7 standard, and contribute to elucidate on the merits and limitations of joint deployment of depth and color in mobile visual search.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Petrelli2015a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{{RGB-D Visual Search}} with {{Compact Binary Codes}}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2015 {{International Conference}} on {{3D Vision}}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Petrelli, Alioscia and Pau, Danilo and Plebani, Emanuele and Di Stefano, Luigi}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{82--90}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/3DV.2015.17}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-4673-8332-5}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Plebani2015" class="col-sm-8"> <div class="title">Training an Object Detector Using Only Positive Samples</div> <div class="author"> <em>Emanuele Plebani</em>, <a href="https://sites.google.com/view/luigicelona" rel="external nofollow noopener" target="_blank">Luigi Celona</a>, <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, <a href="https://www.linkedin.com/in/pegah-karimi-9194b4126" rel="external nofollow noopener" target="_blank">Pegah Karimi</a>, and <a href="https://marconlab.deib.polimi.it/" rel="external nofollow noopener" target="_blank">Marco Marcon</a> </div> <div class="periodical"> <em>In 2015 IEEE 1st International Workshop on Consumer Electronics (CE WS)</em>, Mar 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/CEWS.2015.7867139" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/document/7867139/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Accurate pedestrian detection has an important role in automotive applications because, by issuing warnings to the driver and acting actively on the car brakes, it can save human lives and decrease the probability of injuries. In order to achieve adequate accuracy, detectors require training sets containing a very large number of negative samples, which can be challenging for the training algorithms of models like support vector machines (SVM). A common approach to deal with such large datasets is Hard Negative Mining (HNM), which avoids working on the full set by growing an active pool of mined samples. A more recent method is the Block-Circulant Decomposition, which achieves the accuracy of HNM at a lower computational cost by reformulating the problem in the Fourier domain. The method however results in additional memory, required during training by the FFT transform, which could be reduced significantly by using only the positive examples. To address the problem, this paper proposes two main contributions: (1) it shows that the circulant decomposition method works with the same performances when only the positive samples are used in the training phase (2) it compares the performance of a detection pipeline based on HOG features trained with either both all negative and positive samples or with only positive samples on the INRIA pedestrian dataset.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Plebani2015</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Training an Object Detector Using Only Positive Samples}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2015 {{IEEE}} 1st {{International Workshop}} on {{Consumer Electronics}} ({{CE WS}})}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Plebani, Emanuele and Celona, Luigi and Pau, Danilo and Karimi, Pegah and Marcon, Marco}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--4}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CEWS.2015.7867139}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-5090-4268-5}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2013</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Pau2013" class="col-sm-8"> <div class="title">Mixing Retrieval and Tracking Using Compact Visual Descriptors</div> <div class="author"> <a href="https://www.linkedin.com/in/danilopietropau" rel="external nofollow noopener" target="_blank">Danilo Pau</a>, <a href="https://www.linkedin.com/in/alex-buzzella-988b2854" rel="external nofollow noopener" target="_blank">Alex Buzzella</a>, <a href="https://marconlab.deib.polimi.it/" rel="external nofollow noopener" target="_blank">Marco Marcon</a>, and <em>Emanuele Plebani</em> </div> <div class="periodical"> <em>In IEEE Third International Conference on Consumer Electronics - Berlin (ICCE-Berlin)</em>, Sep 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ICCE-Berlin.2013.6697963" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6697963" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Visual search has seen many improvements over the years, but its application on video content is still an open research problem and it is often limited to still images. Based on the tools devised by the standardization group MPEG CDVS, we developed a processing flow that processes at nearly real-time a video acquired with a low cost imager and performs content search and retrieval of the top match from a local database. To allow efficient interest point detection, we used a GPU accelerated SIFT library. To process the video frames efficiently, we developed a new dataflow processing which allows switching between object searching, retrieving and tracking in order to keep at minimum the number of queries sent to the database. A search into a local database is performed only when no object has been recognized, and once a good match has been found, the algorithm switches to tracking mode.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Pau2013</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mixing Retrieval and Tracking Using Compact Visual Descriptors}</span><span class="p">,</span>
  <span class="na">shorttitle</span> <span class="p">=</span> <span class="s">{Consumer {{Electronics}} ?? {{Berlin}} ({{ICCE-Berlin}}), 2013}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{{IEEE Third International Conference}} on {{Consumer Electronics}} - {{Berlin}} ({{ICCE-Berlin}})}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pau, Danilo and Buzzella, Alex and Marcon, Marco and Plebani, Emanuele}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{103--107}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Berlin, Germany}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICCE-Berlin.2013.6697963}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-4799-1412-8}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Emanuele Plebani. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>